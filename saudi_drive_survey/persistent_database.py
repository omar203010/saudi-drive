#!/usr/bin/env python3
"""
Ø³ÙƒØ±ÙŠØ¨Øª Ø¶Ù…Ø§Ù† Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø³Ø¹ÙˆØ¯ÙŠ Ø¯Ø±Ø§ÙŠÙ
ÙŠØ¶Ù…Ù† Ø¹Ø¯Ù… ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙŠØ­ÙØ¸Ù‡Ø§ Ù„Ù…Ø¯Ø© 5 Ø£Ø´Ù‡Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„
"""

import sqlite3
import os
import shutil
from datetime import datetime, timedelta
import json
import schedule
import time
import threading

class PersistentDatabase:
    def __init__(self):
        self.db_path = '/home/ubuntu/saudi_drive_survey/src/database/app.db'
        self.backup_dir = '/home/ubuntu/saudi_drive_backups'
        self.cloud_backup_dir = '/home/ubuntu/cloud_backups'
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
        os.makedirs(self.backup_dir, exist_ok=True)
        os.makedirs(self.cloud_backup_dir, exist_ok=True)
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        
        # Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self.ensure_database_exists()
        
    def ensure_database_exists(self):
        """Ø¶Ù…Ø§Ù† ÙˆØ¬ÙˆØ¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ù†Ø´Ø§Ø¤Ù‡Ø§ Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©"""
        
        if not os.path.exists(self.db_path):
            print("ğŸ”§ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©...")
            self.create_database()
        else:
            print("âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©")
            
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self.verify_database_integrity()
    
    def create_database(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„"""
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS user (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username VARCHAR(80) UNIQUE NOT NULL,
                    email VARCHAR(120) UNIQUE NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø§Ø³ØªØ¨ÙŠØ§Ù† Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS survey_response (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name VARCHAR(100),
                    gender VARCHAR(10),
                    phone VARCHAR(20),
                    current_app VARCHAR(50),
                    usage_frequency VARCHAR(50),
                    important_factors TEXT,
                    additional_features TEXT,
                    current_problems TEXT,
                    additional_problems TEXT,
                    try_saudi_app VARCHAR(50),
                    preferred_payment TEXT,
                    female_captain_service VARCHAR(100),
                    female_service_suggestions TEXT,
                    customer_suggestions TEXT,
                    ip_address VARCHAR(45),
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Ø¥Ù†Ø´Ø§Ø¡ ÙÙ‡Ø§Ø±Ø³ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_created_at ON survey_response(created_at)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_phone ON survey_response(phone)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_gender ON survey_response(gender)')
            
            conn.commit()
            conn.close()
            
            print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
    
    def verify_database_integrity(self):
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ÙØ­Øµ Ø³Ù„Ø§Ù…Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            cursor.execute('PRAGMA integrity_check')
            result = cursor.fetchone()[0]
            
            if result == 'ok':
                print("âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø³Ù„ÙŠÙ…Ø©")
            else:
                print(f"âš ï¸ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {result}")
                self.repair_database()
            
            conn.close()
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            self.repair_database()
    
    def repair_database(self):
        """Ø¥ØµÙ„Ø§Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ§Ù„ÙØ©"""
        
        print("ğŸ”§ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„ØªØ§Ù„ÙØ©
            backup_corrupted = f"{self.db_path}.corrupted_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            shutil.copy2(self.db_path, backup_corrupted)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù…Ù† Ø¢Ø®Ø± Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            latest_backup = self.get_latest_backup()
            if latest_backup:
                shutil.copy2(latest_backup, self.db_path)
                print(f"âœ… ØªÙ… Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù†: {latest_backup}")
            else:
                # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
                os.remove(self.db_path)
                self.create_database()
                print("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©")
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥ØµÙ„Ø§Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
    
    def get_latest_backup(self):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø­Ø¯Ø« Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        
        try:
            backup_files = []
            for file in os.listdir(self.backup_dir):
                if file.startswith('saudi_drive_backup_') and file.endswith('.db'):
                    file_path = os.path.join(self.backup_dir, file)
                    backup_files.append((file_path, os.path.getctime(file_path)))
            
            if backup_files:
                # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ (Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ø§Ù‹)
                backup_files.sort(key=lambda x: x[1], reverse=True)
                return backup_files[0][0]
            
            return None
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
            return None
    
    def create_backup(self):
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"""
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        try:
            # Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ø­Ù„ÙŠØ©
            local_backup = os.path.join(self.backup_dir, f'saudi_drive_backup_{timestamp}.db')
            shutil.copy2(self.db_path, local_backup)
            
            # Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ Ù…Ø¬Ù„Ø¯ Ù…Ù†ÙØµÙ„ (Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ)
            cloud_backup = os.path.join(self.cloud_backup_dir, f'saudi_drive_cloud_{timestamp}.db')
            shutil.copy2(self.db_path, cloud_backup)
            
            # ØªØµØ¯ÙŠØ± JSON
            self.export_to_json(timestamp)
            
            print(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {timestamp}")
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            self.cleanup_old_backups()
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
    
    def export_to_json(self, timestamp):
        """ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ JSON"""
        
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            cursor.execute('SELECT * FROM survey_response')
            rows = cursor.fetchall()
            
            data = {
                'export_date': datetime.now().isoformat(),
                'total_responses': len(rows),
                'responses': [dict(row) for row in rows]
            }
            
            json_file = os.path.join(self.backup_dir, f'saudi_drive_data_{timestamp}.json')
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            # Ù†Ø³Ø®Ø© JSON ÙÙŠ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠ Ø£ÙŠØ¶Ø§Ù‹
            cloud_json = os.path.join(self.cloud_backup_dir, f'saudi_drive_data_{timestamp}.json')
            shutil.copy2(json_file, cloud_json)
            
            conn.close()
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµØ¯ÙŠØ± JSON: {e}")
    
    def cleanup_old_backups(self):
        """Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù€ 5 Ø£Ø´Ù‡Ø±)"""
        
        # ØªØ§Ø±ÙŠØ® Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ© (5 Ø£Ø´Ù‡Ø±)
        expiry_date = datetime.now() - timedelta(days=150)  # 5 Ø£Ø´Ù‡Ø± ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹
        
        for backup_dir in [self.backup_dir, self.cloud_backup_dir]:
            try:
                for file in os.listdir(backup_dir):
                    if file.startswith('saudi_drive_'):
                        file_path = os.path.join(backup_dir, file)
                        file_time = datetime.fromtimestamp(os.path.getctime(file_path))
                        
                        if file_time < expiry_date:
                            os.remove(file_path)
                            print(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {file}")
                            
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {e}")
    
    def get_statistics(self):
        """Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
            cursor.execute('SELECT COUNT(*) FROM survey_response')
            total = cursor.fetchone()[0]
            
            cursor.execute('SELECT COUNT(*) FROM survey_response WHERE phone IS NOT NULL AND phone != ""')
            with_phone = cursor.fetchone()[0]
            
            cursor.execute('SELECT COUNT(*) FROM survey_response WHERE gender = "Ø°ÙƒØ±"')
            male = cursor.fetchone()[0]
            
            cursor.execute('SELECT COUNT(*) FROM survey_response WHERE gender = "Ø£Ù†Ø«Ù‰"')
            female = cursor.fetchone()[0]
            
            # Ø¢Ø®Ø± Ø±Ø¯
            cursor.execute('SELECT created_at FROM survey_response ORDER BY created_at DESC LIMIT 1')
            last_response = cursor.fetchone()
            
            print("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
            print(f"   ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±Ø¯ÙˆØ¯: {total}")
            print(f"   ğŸ“± Ø±Ø¯ÙˆØ¯ Ù…Ø¹ Ø£Ø±Ù‚Ø§Ù… Ø¬ÙˆØ§Ù„: {with_phone}")
            print(f"   ğŸ‘¨ Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø°ÙƒÙˆØ±: {male}")
            print(f"   ğŸ‘© Ø±Ø¯ÙˆØ¯ Ø§Ù„Ø¥Ù†Ø§Ø«: {female}")
            print(f"   ğŸ• Ø¢Ø®Ø± Ø±Ø¯: {last_response[0] if last_response else 'Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±Ø¯ÙˆØ¯'}")
            
            conn.close()
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")
    
    def start_automatic_backup(self):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
        
        # Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙƒÙ„ Ø³Ø§Ø¹Ø©
        schedule.every().hour.do(self.create_backup)
        
        # Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙŠÙˆÙ…ÙŠØ© ÙÙŠ Ù…Ù†ØªØµÙ Ø§Ù„Ù„ÙŠÙ„
        schedule.every().day.at("00:00").do(self.create_backup)
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø£Ø³Ø¨ÙˆØ¹ÙŠØ§Ù‹
        schedule.every().week.do(self.cleanup_old_backups)
        
        def run_scheduler():
            while True:
                schedule.run_pending()
                time.sleep(60)  # ÙØ­Øµ ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚Ø©
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¬Ø¯ÙˆÙ„ ÙÙŠ Ø®ÙŠØ· Ù…Ù†ÙØµÙ„
        scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
        scheduler_thread.start()
        
        print("ğŸ”„ ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    print("ğŸš€ Ø¨Ø¯Ø¡ Ù†Ø¸Ø§Ù… Ø¶Ù…Ø§Ù† Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø«ÙŠÙ„ Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù…
    db_system = PersistentDatabase()
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    db_system.get_statistics()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙˆØ±ÙŠØ©
    db_system.create_backup()
    
    # Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
    db_system.start_automatic_backup()
    
    print("âœ… Ù†Ø¸Ø§Ù… Ø¶Ù…Ø§Ù† Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø§Ù‡Ø²!")
    print("ğŸ“… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø³ØªÙØ­ÙØ¸ Ù„Ù…Ø¯Ø© 5 Ø£Ø´Ù‡Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„")
    print("ğŸ”„ Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ© ÙƒÙ„ Ø³Ø§Ø¹Ø©")

if __name__ == "__main__":
    main()

